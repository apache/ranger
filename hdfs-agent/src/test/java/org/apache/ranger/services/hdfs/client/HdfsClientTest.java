/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

package org.apache.ranger.services.hdfs.client;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.security.SecureClientLogin;
import org.apache.hadoop.security.UserGroupInformation;
import org.apache.ranger.plugin.client.HadoopException;
import org.junit.jupiter.api.Assertions;
import org.junit.jupiter.api.MethodOrderer;
import org.junit.jupiter.api.Test;
import org.junit.jupiter.api.TestMethodOrder;
import org.junit.jupiter.api.extension.ExtendWith;
import org.mockito.MockedConstruction;
import org.mockito.MockedStatic;
import org.mockito.Mockito;
import org.mockito.junit.jupiter.MockitoExtension;

import javax.security.auth.Subject;

import java.io.FileNotFoundException;
import java.io.IOException;
import java.net.UnknownHostException;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import static org.junit.jupiter.api.Assertions.assertThrows;

/**
 * @generated by Cursor
 * @description : Unit Test cases for HdfsClient
 */

@TestMethodOrder(MethodOrderer.MethodName.class)
@ExtendWith(MockitoExtension.class)
public class HdfsClientTest {
    @Test
    public void testUsernameNotSpecified() throws IllegalArgumentException {
        Map<String, String> configs = new HashMap<>();
        assertInvalidConfig(configs);
    }

    @Test
    public void testPasswordNotSpecified() throws IllegalArgumentException {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        assertInvalidConfig(configs);
    }

    @Test
    public void testAuthenticationNotSpecified() throws IllegalArgumentException {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        assertInvalidConfig(configs);
    }

    @Test
    public void testFsDefaultNameNotSpecified() throws IllegalArgumentException {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        assertInvalidConfig(configs);
    }

    @Test
    public void testProxyProviderNotSpecified() throws IllegalArgumentException {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "hdfs://hwqe-1425428405");
        configs.put("dfs.nameservices", "hwqe-1425428405");
        assertInvalidConfig(configs);
    }

    @Test
    public void testNnElementsNotSpecified() throws IllegalArgumentException {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "hdfs://hwqe-1425428405");
        configs.put("dfs.nameservices", "hwqe-1425428405");
        configs.put("dfs.client.failover.proxy.provider.hwqe-1425428405", "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider");
        assertInvalidConfig(configs);
    }

    @Test
    public void testNn1UrlNn2UrlNotSpecified() throws IllegalArgumentException {
        Map<String, String> configs = new HashMap<>();

        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "hdfs://hwqe-1425428405");
        configs.put("dfs.nameservices", "hwqe-1425428405");
        configs.put("dfs.client.failover.proxy.provider.hwqe-1425428405", "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider");
        configs.put("dfs.ha.namenodes.hwqe-1425428405", "nn1,nn2");

        assertInvalidConfig(configs);
    }

    @Test
    public void testNn1UrlNotSpecified() throws IllegalArgumentException {
        Map<String, String> configs = new HashMap<>();

        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "hdfs://hwqe-1425428405");
        configs.put("dfs.nameservices", "hwqe-1425428405");
        configs.put("dfs.client.failover.proxy.provider.hwqe-1425428405", "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider");
        configs.put("dfs.ha.namenodes.hwqe-1425428405", "nn1,nn2");
        configs.put("dfs.namenode.rpc-address.hwqe-1425428405.nn2", "node-2.example.com:8020");

        assertInvalidConfig(configs);
    }

    @Test
    public void testNn2UrlNotSpecified() throws IllegalArgumentException {
        Map<String, String> configs = new HashMap<>();

        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "hdfs://hwqe-1425428405");
        configs.put("dfs.nameservices", "hwqe-1425428405");
        configs.put("dfs.client.failover.proxy.provider.hwqe-1425428405", "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider");
        configs.put("dfs.ha.namenodes.hwqe-1425428405", "nn1,nn2");
        configs.put("dfs.namenode.rpc-address.hwqe-1425428405.nn1", "node-1.example.com:8020");

        assertInvalidConfig(configs);
    }

    @Test
    public void testValidNonHaConfig() throws IllegalArgumentException {
        // username: hdfsuser
        // password: hdfsuser
        // hadoop.security.authentication: simple
        // fs.default.name: hdfs://node-2.example.com:8020

        Map<String, String> configs = new HashMap<>();

        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "hdfs://node-2.example.com:8020");

        HdfsClient.validateConnectionConfigs(configs);
    }

    @Test
    public void testValidHaConfig() throws IllegalArgumentException {
        // username: hdfsuser
        // password: hdfsuser
        // hadoop.security.authentication: simple
        // dfs.nameservices: hwqe-1425428405
        // fs.default.name:
        // dfs.ha.namenodes.hwqe-1425428405: nn1,nn2
        // dfs.namenode.rpc-address.hwqe-1425428405.nn2: node-2.example.com:8020
        // dfs.namenode.rpc-address.hwqe-1425428405.nn1:  node-1.example.com:8020

        Map<String, String> configs = new HashMap<>();

        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "hdfs://hwqe-1425428405");
        configs.put("dfs.nameservices", "hwqe-1425428405");
        configs.put("dfs.client.failover.proxy.provider.hwqe-1425428405", "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider");
        configs.put("dfs.ha.namenodes.hwqe-1425428405", "nn1,nn2");
        configs.put("dfs.namenode.rpc-address.hwqe-1425428405.nn1", "node-1.example.com:8020");
        configs.put("dfs.namenode.rpc-address.hwqe-1425428405.nn2", "node-2.example.com:8020");

        HdfsClient.validateConnectionConfigs(configs);
    }

    // ===== JUnit 5 additional tests appended (preserving existing code above) =====

    @Test
    public void test_validate_valid_multi_nn_transforms_config() {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "node-1.example.com:8020,node-2.example.com:8020");
        HdfsClient.validateConnectionConfigs(configs);
        Assertions.assertEquals("hdfscluster", configs.get("dfs.nameservices"));
        Assertions.assertEquals("hdfs://hdfscluster", configs.get("fs.default.name"));
        Assertions.assertEquals("org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider", configs.get("dfs.client.failover.proxy.provider.hdfscluster"));
        Assertions.assertEquals("namenode1,namenode2", configs.get("dfs.ha.namenodes.hdfscluster"));
        Assertions.assertEquals("node-1.example.com:8020", configs.get("dfs.namenode.rpc-address.hdfscluster.namenode1"));
        Assertions.assertEquals("node-2.example.com:8020", configs.get("dfs.namenode.rpc-address.hdfscluster.namenode2"));
    }

    @Test
    public void test01_validate_username_missing() {
        Map<String, String>      configs = new HashMap<>();
        IllegalArgumentException ex      = Assertions.assertThrows(IllegalArgumentException.class, () -> HdfsClient.validateConnectionConfigs(configs));
        Assertions.assertTrue(ex.getMessage().contains("username"));
    }

    @Test
    public void test02_validate_password_missing() {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        IllegalArgumentException ex = Assertions.assertThrows(IllegalArgumentException.class, () -> HdfsClient.validateConnectionConfigs(configs));
        Assertions.assertTrue(ex.getMessage().contains("password"));
    }

    @Test
    public void test03_validate_auth_missing() {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        IllegalArgumentException ex = Assertions.assertThrows(IllegalArgumentException.class, () -> HdfsClient.validateConnectionConfigs(configs));
        Assertions.assertTrue(ex.getMessage().contains("hadoop.security.authentication"));
    }

    @Test
    public void test04_validate_fsdefault_missing() {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        IllegalArgumentException ex = Assertions.assertThrows(IllegalArgumentException.class, () -> HdfsClient.validateConnectionConfigs(configs));
        Assertions.assertTrue(ex.getMessage().contains("fs.default.name"));
    }

    @Test
    public void test05_validate_proxyProvider_missing() {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "hdfs://hwqe-1425428405");
        configs.put("dfs.nameservices", "hwqe-1425428405");
        IllegalArgumentException ex = Assertions.assertThrows(IllegalArgumentException.class, () -> HdfsClient.validateConnectionConfigs(configs));
        Assertions.assertTrue(ex.getMessage().contains("dfs.client.failover.proxy.provider.hwqe-1425428405"));
    }

    @Test
    public void test06_validate_nnElements_missing() {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "hdfs://hwqe-1425428405");
        configs.put("dfs.nameservices", "hwqe-1425428405");
        configs.put("dfs.client.failover.proxy.provider.hwqe-1425428405", "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider");
        IllegalArgumentException ex = Assertions.assertThrows(IllegalArgumentException.class, () -> HdfsClient.validateConnectionConfigs(configs));
        Assertions.assertTrue(ex.getMessage().contains("dfs.ha.namenodes.hwqe-1425428405"));
    }

    @Test
    public void test07_validate_nn1_missing() {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "hdfs://hwqe-1425428405");
        configs.put("dfs.nameservices", "hwqe-1425428405");
        configs.put("dfs.client.failover.proxy.provider.hwqe-1425428405", "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider");
        configs.put("dfs.ha.namenodes.hwqe-1425428405", "nn1,nn2");
        configs.put("dfs.namenode.rpc-address.hwqe-1425428405.nn2", "node-2.example.com:8020");
        IllegalArgumentException ex = Assertions.assertThrows(IllegalArgumentException.class, () -> HdfsClient.validateConnectionConfigs(configs));
        Assertions.assertTrue(ex.getMessage().contains("dfs.namenode.rpc-address.hwqe-1425428405.nn1"));
    }

    @Test
    public void test08_validate_nn2_missing() {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "hdfs://hwqe-1425428405");
        configs.put("dfs.nameservices", "hwqe-1425428405");
        configs.put("dfs.client.failover.proxy.provider.hwqe-1425428405", "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider");
        configs.put("dfs.ha.namenodes.hwqe-1425428405", "nn1,nn2");
        configs.put("dfs.namenode.rpc-address.hwqe-1425428405.nn1", "node-1.example.com:8020");
        IllegalArgumentException ex = Assertions.assertThrows(IllegalArgumentException.class, () -> HdfsClient.validateConnectionConfigs(configs));
        Assertions.assertTrue(ex.getMessage().contains("dfs.namenode.rpc-address.hwqe-1425428405.nn2"));
    }

    @Test
    public void test09_validate_valid_non_ha() {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "hdfs://node-2.example.com:8020");
        HdfsClient.validateConnectionConfigs(configs);
    }

    @Test
    public void test10_validate_valid_multi_nn_transforms_config() {
        Map<String, String> configs = new HashMap<>();
        configs.put("username", "hdfsuser");
        configs.put("password", "hdfsuser");
        configs.put("hadoop.security.authentication", "simple");
        configs.put("fs.default.name", "node-1.example.com:8020,node-2.example.com:8020");
        HdfsClient.validateConnectionConfigs(configs);
        Assertions.assertEquals("hdfscluster", configs.get("dfs.nameservices"));
        Assertions.assertEquals("hdfs://hdfscluster", configs.get("fs.default.name"));
        Assertions.assertEquals("org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider", configs.get("dfs.client.failover.proxy.provider.hdfscluster"));
        Assertions.assertEquals("namenode1,namenode2", configs.get("dfs.ha.namenodes.hdfscluster"));
        Assertions.assertEquals("node-1.example.com:8020", configs.get("dfs.namenode.rpc-address.hdfscluster.namenode1"));
        Assertions.assertEquals("node-2.example.com:8020", configs.get("dfs.namenode.rpc-address.hdfscluster.namenode2"));
    }

    @Test
    public void test11_connectionTest_success() throws Exception {
        Map<String, String> cfg = new HashMap<>();
        cfg.put("username", "u");
        cfg.put("password", "p");
        cfg.put("hadoop.security.authentication", "simple");
        cfg.put("fs.default.name", "hdfs://node-1:8020");

        try (MockedStatic<SecureClientLogin> mockedLogin = Mockito.mockStatic(SecureClientLogin.class);
                MockedStatic<UserGroupInformation> mockedUGI = Mockito.mockStatic(UserGroupInformation.class);
                MockedStatic<FileSystem> mockedFS = Mockito.mockStatic(FileSystem.class)) {
            mockedLogin.when(() -> SecureClientLogin.getPrincipal(Mockito.anyString(), Mockito.anyString())).thenReturn(null);
            mockedLogin.when(() -> SecureClientLogin.login(Mockito.anyString())).thenReturn(new Subject());

            try (MockedConstruction<HdfsClient> mockedConstruct = Mockito.mockConstruction(HdfsClient.class, (mock, ctx) -> {
                Mockito.when(mock.listFiles(Mockito.eq("/"), Mockito.isNull(), Mockito.isNull())).thenReturn(Collections.singletonList("/a"));
            })) {
                Map<String, Object> ret = HdfsClient.connectionTest("svc", cfg);
                Assertions.assertEquals(Boolean.TRUE, ret.get("connectivityStatus"));
            }
        }
    }

    @Test
    public void test12_connectionTest_unableToListFiles() throws Exception {
        Map<String, String> cfg = new HashMap<>();
        cfg.put("username", "u");
        cfg.put("password", "p");
        cfg.put("hadoop.security.authentication", "simple");
        cfg.put("fs.default.name", "hdfs://node-1:8020");

        try (MockedStatic<SecureClientLogin> mockedLogin = Mockito.mockStatic(SecureClientLogin.class);
                MockedStatic<UserGroupInformation> mockedUGI = Mockito.mockStatic(UserGroupInformation.class);
                MockedStatic<FileSystem> mockedFS = Mockito.mockStatic(FileSystem.class)) {
            mockedLogin.when(() -> SecureClientLogin.getPrincipal(Mockito.anyString(), Mockito.anyString())).thenReturn(null);
            mockedLogin.when(() -> SecureClientLogin.login(Mockito.anyString())).thenReturn(new Subject());

            try (MockedConstruction<HdfsClient> mockedConstruct = Mockito.mockConstruction(HdfsClient.class, (mock, ctx) -> {
                Mockito.when(mock.listFiles(Mockito.eq("/"), Mockito.isNull(), Mockito.isNull())).thenReturn(Collections.emptyList());
            })) {
                Map<String, Object> ret = HdfsClient.connectionTest("svc", cfg);
                Assertions.assertEquals(Boolean.FALSE, ret.get("connectivityStatus"));
            }
        }
    }

    @Test
    public void test13_connectionTest_propagates_hadoop_exception() throws Exception {
        Map<String, String> cfg = new HashMap<>();
        cfg.put("username", "u");
        cfg.put("password", "p");
        cfg.put("hadoop.security.authentication", "simple");
        cfg.put("fs.default.name", "hdfs://node-1:8020");

        try (MockedStatic<SecureClientLogin> mockedLogin = Mockito.mockStatic(SecureClientLogin.class);
                MockedStatic<UserGroupInformation> mockedUGI = Mockito.mockStatic(UserGroupInformation.class);
                MockedStatic<FileSystem> mockedFS = Mockito.mockStatic(FileSystem.class)) {
            mockedLogin.when(() -> SecureClientLogin.getPrincipal(Mockito.anyString(), Mockito.anyString())).thenReturn(null);
            mockedLogin.when(() -> SecureClientLogin.login(Mockito.anyString())).thenReturn(new Subject());

            try (MockedConstruction<HdfsClient> mockedConstruct = Mockito.mockConstruction(HdfsClient.class, (mock, ctx) -> {
                Mockito.when(mock.listFiles(Mockito.eq("/"), Mockito.isNull(), Mockito.isNull())).thenThrow(new HadoopException("x", new RuntimeException("y")));
            })) {
                Assertions.assertThrows(HadoopException.class, () -> HdfsClient.connectionTest("svc", cfg));
            }
        }
    }

    @Test
    public void test14_listFiles_returns_base_when_empty_listing_and_exists() throws Exception {
        Map<String, String> cfg = baseCfg();
        try (MockedStatic<SecureClientLogin> mockedLogin = Mockito.mockStatic(SecureClientLogin.class);
                MockedStatic<UserGroupInformation> mockedUGI = Mockito.mockStatic(UserGroupInformation.class);
                MockedStatic<FileSystem> mockedFS = Mockito.mockStatic(FileSystem.class)) {
            mockedLogin.when(() -> SecureClientLogin.getPrincipal(Mockito.anyString(), Mockito.anyString())).thenReturn(null);
            mockedLogin.when(() -> SecureClientLogin.login(Mockito.anyString())).thenReturn(new Subject());

            FileSystem fs = Mockito.mock(FileSystem.class);
            mockedFS.when(() -> FileSystem.get(Mockito.any(Configuration.class))).thenReturn(fs);

            Path base = new Path("/base");
            Mockito.when(fs.listStatus(Mockito.eq(base))).thenReturn(new FileStatus[0]);
            Mockito.when(fs.exists(Mockito.eq(base))).thenReturn(true);

            HdfsClient   client = new HdfsClient("svc", cfg);
            List<String> out    = client.listFiles("/base", null, null);
            Assertions.assertEquals(Collections.singletonList("/base"), out);
        }
    }

    @Test
    public void test15_listFiles_filters_and_skips_duplicates() throws Exception {
        Map<String, String> cfg = baseCfg();
        try (MockedStatic<SecureClientLogin> mockedLogin = Mockito.mockStatic(SecureClientLogin.class);
                MockedStatic<UserGroupInformation> mockedUGI = Mockito.mockStatic(UserGroupInformation.class);
                MockedStatic<FileSystem> mockedFS = Mockito.mockStatic(FileSystem.class)) {
            mockedLogin.when(() -> SecureClientLogin.getPrincipal(Mockito.anyString(), Mockito.anyString())).thenReturn(null);
            mockedLogin.when(() -> SecureClientLogin.login(Mockito.anyString())).thenReturn(new Subject());

            FileSystem fs = Mockito.mock(FileSystem.class);
            mockedFS.when(() -> FileSystem.get(Mockito.any(Configuration.class))).thenReturn(fs);

            Path       base = new Path("/base");
            FileStatus stA  = Mockito.mock(FileStatus.class);
            FileStatus stB  = Mockito.mock(FileStatus.class);
            Mockito.when(stA.getPath()).thenReturn(new Path("/base/a"));
            Mockito.when(stB.getPath()).thenReturn(new Path("/base/b"));
            Mockito.when(fs.listStatus(Mockito.eq(base))).thenReturn(new FileStatus[] {stA, stB});
            Mockito.when(fs.exists(Mockito.eq(base))).thenReturn(true);

            HdfsClient   client      = new HdfsClient("svc", cfg);
            List<String> outNoFilter = client.listFiles("/base", null, Collections.singletonList("/base/a"));
            Assertions.assertEquals(Collections.singletonList("/base/b"), outNoFilter);

            List<String> outWithFilter = client.listFiles("/base", "*.txt", new ArrayList<>());
            // for filter, set statuses to .txt and .log
            FileStatus stTxt = Mockito.mock(FileStatus.class);
            FileStatus stLog = Mockito.mock(FileStatus.class);
            Mockito.when(stTxt.getPath()).thenReturn(new Path("/base/file.txt"));
            Mockito.when(stLog.getPath()).thenReturn(new Path("/base/file.log"));
            Mockito.when(fs.listStatus(Mockito.eq(base))).thenReturn(new FileStatus[] {stTxt, stLog});
            List<String> filtered = client.listFiles("/base", "*.txt", new ArrayList<>());
            Assertions.assertEquals(Collections.singletonList("/base/file.txt"), filtered);
        }
    }

    @Test
    public void test16_listFiles_wraps_unknown_host() throws Exception {
        Map<String, String> cfg = baseCfg();
        try (MockedStatic<SecureClientLogin> mockedLogin = Mockito.mockStatic(SecureClientLogin.class);
                MockedStatic<UserGroupInformation> mockedUGI = Mockito.mockStatic(UserGroupInformation.class);
                MockedStatic<FileSystem> mockedFS = Mockito.mockStatic(FileSystem.class)) {
            mockedLogin.when(() -> SecureClientLogin.getPrincipal(Mockito.anyString(), Mockito.anyString())).thenReturn(null);
            mockedLogin.when(() -> SecureClientLogin.login(Mockito.anyString())).thenReturn(new Subject());

            mockedFS.when(() -> FileSystem.get(Mockito.any(Configuration.class))).thenThrow(new UnknownHostException("unresolvable"));

            HdfsClient client = new HdfsClient("svc", cfg);
            Assertions.assertThrows(HadoopException.class, () -> client.listFiles("/base", null, null));
        }
    }

    @Test
    public void test17_listFiles_wraps_file_not_found() throws Exception {
        Map<String, String> cfg = baseCfg();
        try (MockedStatic<SecureClientLogin> mockedLogin = Mockito.mockStatic(SecureClientLogin.class);
                MockedStatic<UserGroupInformation> mockedUGI = Mockito.mockStatic(UserGroupInformation.class);
                MockedStatic<FileSystem> mockedFS = Mockito.mockStatic(FileSystem.class)) {
            mockedLogin.when(() -> SecureClientLogin.getPrincipal(Mockito.anyString(), Mockito.anyString())).thenReturn(null);
            mockedLogin.when(() -> SecureClientLogin.login(Mockito.anyString())).thenReturn(new Subject());

            FileSystem fs = Mockito.mock(FileSystem.class);
            mockedFS.when(() -> FileSystem.get(Mockito.any(Configuration.class))).thenReturn(fs);

            Mockito.when(fs.listStatus(Mockito.any(Path.class))).thenThrow(new FileNotFoundException("missing"));

            HdfsClient client = new HdfsClient("svc", cfg);
            Assertions.assertThrows(HadoopException.class, () -> client.listFiles("/base", null, null));
        }
    }

    @Test
    public void test18_listFiles_wraps_io_exception() throws Exception {
        Map<String, String> cfg = baseCfg();
        try (MockedStatic<SecureClientLogin> mockedLogin = Mockito.mockStatic(SecureClientLogin.class);
                MockedStatic<UserGroupInformation> mockedUGI = Mockito.mockStatic(UserGroupInformation.class);
                MockedStatic<FileSystem> mockedFS = Mockito.mockStatic(FileSystem.class)) {
            mockedLogin.when(() -> SecureClientLogin.getPrincipal(Mockito.anyString(), Mockito.anyString())).thenReturn(null);
            mockedLogin.when(() -> SecureClientLogin.login(Mockito.anyString())).thenReturn(new Subject());

            FileSystem fs = Mockito.mock(FileSystem.class);
            mockedFS.when(() -> FileSystem.get(Mockito.any(Configuration.class))).thenReturn(fs);

            Mockito.when(fs.listStatus(Mockito.any(Path.class))).thenThrow(new IOException("io"));

            HdfsClient client = new HdfsClient("svc", cfg);
            Assertions.assertThrows(HadoopException.class, () -> client.listFiles("/base", null, null));
        }
    }

    private void assertInvalidConfig(Map<String, String> configs) {
        assertThrows(IllegalArgumentException.class, () -> HdfsClient.validateConnectionConfigs(configs));
    }

    private Map<String, String> baseCfg() {
        Map<String, String> cfg = new HashMap<>();
        cfg.put("username", "u");
        cfg.put("password", "p");
        cfg.put("hadoop.security.authentication", "simple");
        cfg.put("fs.default.name", "hdfs://node-1:8020");
        return cfg;
    }
}
