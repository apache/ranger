# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

FROM ubuntu:20.04

ENV RANGER_VERSION 3.0.0-SNAPSHOT
ENV HADOOP_VERSION 3.1.1
ENV HIVE_VERSION   3.1.2

# Install curl, wget, tzdata, Python, Java, python-requests
RUN apt-get update && \
    DEBIAN_FRONTEND="noninteractive" apt-get -y install vim sudo curl wget tzdata python python3 python3-pip openjdk-8-jdk bc iputils-ping ssh pdsh && \
    curl https://bootstrap.pypa.io/get-pip.py --output /tmp/get-pip.py && \
    python2 /tmp/get-pip.py && \
    pip3 install requests && \
    pip install requests

RUN groupadd hadoop && \
    useradd -g hadoop -ms /bin/bash hdfs && \
    useradd -g hadoop -ms /bin/bash hive && \
    mkdir -p /opt/ranger && \
    mkdir -p /home/ranger/dist && \
    mkdir -p /home/ranger/scripts


COPY ./dist/version                                     /home/ranger/dist/
COPY ./dist/ranger-${RANGER_VERSION}-hdfs-plugin.tar.gz /home/ranger/dist/
COPY ./scripts/ranger-hadoop-setup.sh                   /home/ranger/scripts/
COPY ./scripts/ranger-hadoop.sh                         /home/ranger/scripts/
COPY ./scripts/ranger-hdfs-plugin-install.properties    /home/ranger/scripts/

RUN curl https://archive.apache.org/dist/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz  --output /tmp/hadoop-${HADOOP_VERSION}.tar.gz && \
    tar xvfz /tmp/hadoop-${HADOOP_VERSION}.tar.gz --directory=/opt/ && \
    ln -s /opt/hadoop-${HADOOP_VERSION} /opt/hadoop && \
    rm -f /tmp/hadoop-${HADOOP_VERSION}.tar.gz && \
    tar xvfz /home/ranger/dist/ranger-${RANGER_VERSION}-hdfs-plugin.tar.gz --directory=/opt/ranger && \
    ln -s /opt/ranger/ranger-${RANGER_VERSION}-hdfs-plugin /opt/ranger/ranger-hdfs-plugin && \
    rm -f /home/ranger/dist/ranger-${RANGER_VERSION}-hdfs-plugin.tar.gz && \
    cp -f /home/ranger/scripts/ranger-hdfs-plugin-install.properties /opt/ranger/ranger-hdfs-plugin/install.properties

ENV JAVA_HOME      /usr/lib/jvm/java-8-openjdk-amd64
ENV RANGER_DIST    /home/ranger/dist
ENV RANGER_SCRIPTS /home/ranger/scripts
ENV RANGER_HOME    /opt/ranger

ENV HADOOP_HOME        /opt/hadoop
ENV HADOOP_CONF_DIR    /opt/hadoop/etc/hadoop
ENV HADOOP_HDFS_HOME   /opt/hadoop
ENV HADOOP_MAPRED_HOME /opt/hadoop
ENV HADOOP_COMMON_HOME /opt/hadoop
ENV YARN_HOME          /opt/hadoop
ENV PATH /usr/java/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/hadoop/bin

# COPY ./dist/ranger-${RANGER_VERSION}-hive-plugin.tar.gz /home/ranger/dist/
#
# RUN curl https://archive.apache.org/dist/hive/hive-${HIVE_VERSION}/apache-hive-${HIVE_VERSION}-bin.tar.gz --output /tmp/apache-hive-${HIVE_VERSION}-bin.tar.gz &&
#     tar xvfz /tmp/apache-hive-${HIVE_VERSION}-bin.tar.gz --directory=/opt/ && \
#     ln -s /opt/apache-hive-${HIVE_VERSION}-bin /opt/hive && \
#     rm -f /tmp/apache-hive-${HIVE_VERSION}-bin.tar.gz && \
#     tar xvfz /home/ranger/dist/ranger-${RANGER_VERSION}-hive-plugin.tar.gz --directory=/opt/ranger && \
#     ln -s /opt/ranger/ranger-${RANGER_VERSION}-hive-plugin /opt/ranger/ranger-hive-plugin && \
#     rm -f /home/ranger/dist/ranger-${RANGER_VERSION}-hive-plugin.tar.gz
# ENV HIVE_HOME        /opt/hive
# ENV HIVE_CONF_DIR    /opt/hive/conf
# ENV PATH /usr/java/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/hadoop/bin:/opt/hive/bin

ENTRYPOINT [ "/home/ranger/scripts/ranger-hadoop.sh" ]
